{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Sentinel 2 data from [SciHub](https://scihub.copernicus.eu/dhus) \n",
    "(other missions are available...)\n",
    "\n",
    "Based upon:\n",
    "http://geoinformaticstutorial.blogspot.com/2015/10/batch-downloading-sentinel-images-from.html\n",
    "\n",
    "Adjustments were required to switch to python 3:\n",
    "* urllib2 is now part of urllib\n",
    "* specifying that the text file needed to write to binary \n",
    "\n",
    "        textfile = open('data/test.xml', 'wb')   \n",
    "\n",
    "Also, the request string needed to be modified to include brackets around the search string eg.\n",
    "\n",
    "        ?q=( <search string in here>)\n",
    "The code was further modified to accept a shapefile (or other geographic format) from which the bounding box for the request query could be made.  \n",
    "\n",
    "Note that a login is required for SciHub, so this would need to be set up first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from urllib import request\n",
    "import xml.etree.ElementTree as etree\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Username and password information are stored in a separate module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gets the bounding box of the supplied extents file.  It makes sure that the returned bounding box is in WGS84 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwgs84bbox(extentfile):\n",
    "    \"\"\"\n",
    "    get the bounding box of all features from a shapefile or other \n",
    "    geographic data format supported by geopandas.\n",
    "    Returns the bbox in wkt format\n",
    "    \"\"\"\n",
    "\n",
    "    gdf = gpd.read_file(extentfile)\n",
    "\n",
    "    # convert to wgs\n",
    "    gdf = gdf.to_crs({'init': 'epsg:4326'})    \n",
    "    \n",
    "    bboxlist = gdf.total_bounds\n",
    "\n",
    "    minx = bboxlist[0]\n",
    "    miny = bboxlist[1]\n",
    "    maxx = bboxlist[2]\n",
    "    maxy = bboxlist[3]\n",
    "\n",
    "    botleft  = f\"{minx} {miny}\"\n",
    "    topleft  = f\"{minx} {maxy}\"\n",
    "    topright = f\"{maxx} {maxy}\"\n",
    "    botright = f\"{maxx} {miny}\"\n",
    "\n",
    "    # usually outer polygon rings go in a clockwise direction\n",
    "    # the website returned a polygon drawn in an anti-clockwise direction from a drawn rectangle so this has been replicated.\n",
    "    bboxs = f\"POLYGON(({botleft},{botright},{topright},{topleft},{botleft}))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is the one that actually makes the request to SciHub and downloads files according to the response.\n",
    "\n",
    "It builds a string from the inputs that is used to make a request to SciHub.  The response is in xml and this is parsed to pick out information used to build the url to download the imagery.\n",
    "\n",
    "Note that if a file has already been downloaded, it won't be requested again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentinel_lookout(extentfile, startdate, enddate, \n",
    "        platform, product, cloudcover):\n",
    "    \"\"\"\n",
    "    Search for and download Sentinel files from SciHub\n",
    "    Parameters\n",
    "    ----------\n",
    "    extentfile : string\n",
    "        Path to extent file.  This can be a shapefile or other dataset that \n",
    "        geopandas can read\n",
    "    startdate : string\n",
    "        The start date for the search in the format YYYY-MM-DD\n",
    "    enddate : string\n",
    "        The end date for the search in the format YYYY-MM-DD\n",
    "    platform : string\n",
    "        The Sentinel platform eg Sentinel-2\n",
    "    product : string\n",
    "        The product to use in the search\n",
    "    cloudcover : string\n",
    "        The percentage cloud cover to use in the search.\n",
    "        Must be in the format [<start percentage> <end percentage>]\n",
    "    \"\"\"\n",
    "\n",
    "    # get the bounding box\n",
    "    bbox = getwgs84bbox(extentfile)\n",
    "\n",
    "    # build the date element\n",
    "    sdate = f\"[{startdate}T00:00:00.000Z TO {enddate}T23:59:59.999Z]\"\n",
    "    edate = f\"[{startdate}T00:00:00.000Z TO {enddate}T23:59:59.999Z]\"\n",
    "\n",
    "    # authenticate at scihub webpage\n",
    "    url =  'https://scihub.copernicus.eu/dhus/'\n",
    "    username = info.username\n",
    "    password = info.password\n",
    "    password_mgr = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "\n",
    "    password_mgr.add_password(None, url, username, password)\n",
    "    handler = request.HTTPBasicAuthHandler(password_mgr)\n",
    "    opener = request.build_opener(handler)\n",
    "    request.install_opener(opener)\n",
    "\n",
    "    requeststring = f'''{url}search?q=( footprint:\"Intersects({bbox})\" ) \n",
    "                        AND ( beginPosition:{sdate} \n",
    "                        AND endPosition:{edate} ) \n",
    "                        AND (platformname:{platform} \n",
    "                        AND producttype:{product} \n",
    "                        AND cloudcoverpercentage:{cloudcover})'''\n",
    "\n",
    "    urlrequest = request.quote(requeststring,\n",
    "                            ':()[]/?=,&')\n",
    "    # read the response into page and write it to a xml-file\n",
    "    page = request.urlopen(urlrequest).read()\n",
    "    textfile = open('data/response.xml', 'wb')\n",
    "    textfile.write(page)\n",
    "    textfile.close()\n",
    "\n",
    "    # parse the xml file\n",
    "    # the entry tag contains the results\n",
    "    tree = etree.parse('data/response.xml')\n",
    "    entries = tree.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    print (\"Number of Scenes Found: \", len(entries))\n",
    "    for entry in range(len(entries)):\n",
    "        # the uuid element is used to create the path to the file\n",
    "        uuid_elem = entries[entry].find('{http://www.w3.org/2005/Atom}id')\n",
    "        sentinel_link = f\"https://scihub.copernicus.eu/dhus/odata/v1/Products('{uuid_elem.text}')/$value\"\n",
    "        \n",
    "        # the title element contains the corresponding file name\n",
    "        title_elem = entries[entry].find('{http://www.w3.org/2005/Atom}title')\n",
    "        \n",
    "        # destinationpath with filename where download to be stored\n",
    "        destinationpath =  f\"data/{title_elem.text}.zip\"\n",
    "        \n",
    "        print(f\"Scene {entry + 1} of {len(entries)}\")\n",
    "        \n",
    "        # check if file has already been downloaded\n",
    "        print (sentinel_link)\n",
    "        if os.path.exists(destinationpath):\n",
    "            print (title_elem.text, 'already downloaded')\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        # if not, download file and read\n",
    "        print (\"Downloading \", title_elem.text)\n",
    "        downloadfile = request.urlopen(sentinel_link)\n",
    "        data =  downloadfile.read()\n",
    "        \n",
    "        # write the download into the destination zipfile\n",
    "        with open(destinationpath, \"wb\") as code:\n",
    "            code.write(data)\n",
    "\n",
    "    print (\"Download complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run the code to carry out the download, supplying:\n",
    "* the start and end dates of the search, \n",
    "* a file specifying the area of interest,\n",
    "* the satellite platform,\n",
    "* the specific product,\n",
    "* the percentage cloud cover.  Note the specific format required for this input (eg [0 TO 9.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = \"2018-06-15\"\n",
    "enddate = \"2018-07-22\"\n",
    "extentfile = \"data/iow_mask.shp\"\n",
    "platform = \"Sentinel-2\"\n",
    "product = \"S2MSI2A\"\n",
    "cloudcover = \"[0 TO 5]\"\n",
    "\n",
    "sentinel_lookout(extentfile, startdate, enddate, platform, product, cloudcover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functionality could be modified so that bounding boxes of available images are derived from the xml response.  These extents could then be used to decide which files to actually download.\n",
    "\n",
    "This is the line in the xml response that could be used for that:\n",
    "    \n",
    "    <str name=\"footprint\">POLYGON ((-1.561123205595257 51.44235231685392,0.017025008525814 51.41234265506691,-0.046130286859295 50.42629366061962,-1.591284890362356 50.45527216066188,-1.561123205595257 51.44235231685392))</str>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
